# Ultralytics YOLO

以下是有关使用Ultralytics YOLO模型进行推理的信息，涵盖了`stream`参数的用法以及可用的不同输入源类型：

### 使用`stream`参数

在使用YOLO模型进行推理时，可以通过`stream`参数控制返回结果的方式：

- **`stream=False`**: 返回一个包含所有推理结果的Python列表。适用于处理较小的数据集或单张图片。
- **`stream=True`**: 返回一个内存高效的Python生成器，逐个生成推理结果。适用于处理长视频或大型数据集，以有效管理内存。

```python
from ultralytics import YOLO

# 加载模型
model = YOLO('yolov8n.pt')  # 预训练的YOLOv8n模型

# 在一组图像上运行批量推理
results = model(['im1.jpg', 'im2.jpg'], stream=True)  # 返回结果对象的生成器

# 处理结果生成器
for result in results:
    boxes = result.boxes  # 边界框输出的Boxes对象
    masks = result.masks  # 分割掩码输出的Masks对象
    keypoints = result.keypoints  # 姿态输出的Keypoints对象
    probs = result.probs  # 分类输出的Probs对象
    result.show()  # 显示到屏幕
    result.save(filename='result.jpg')  # 保存到磁盘
```

### 支持的输入源

YOLOv8可以处理多种类型的输入源进行推理，下表列出了支持的输入源类型和相关注意事项，包括哪些源可以在流模式下使用（`stream=True`）：

| 源        | 参数例子                                | 类型              | 备注                                                |
|---------|---------------------------------------|------------------|---------------------------------------------------|
| 图片      | 'image.jpg'                           | str or Path      | 单个图像文件。                                           |
| URL      | 'https://ultralytics.com/images/bus.jpg' | str             | 图像的URL。                                           |
| 截屏      | 'screen'                              | str              | 捕捉屏幕截图。                                           |
| PIL图像   | Image.open('im.jpg')                  | PIL.Image        | HWC格式，RGB通道。                                      |
| OpenCV图像 | cv2.imread('im.jpg')                 | np.ndarray       | HWC格式，BGR通道，uint8 (0-255)。                        |
| numpy数组 | np.zeros((640, 1280, 3))              | np.ndarray       | HWC格式，BGR通道，uint8 (0-255)。                        |
| torch张量 | torch.zeros(16, 3, 320, 640)          | torch.Tensor     | BCHW格式，RGB通道，float32 (0.0-1.0)。                  |
| CSV文件   | 'sources.csv'                         | str or Path      | 包含图像、视频或目录路径的CSV文件。                        |
| 视频 ✅    | 'video.mp4'                           | str or Path      | 支持MP4、AVI等格式的视频文件。可以在流模式下使用。          |
| 目录 ✅    | 'path/'                               | str or Path      | 包含图像或视频的目录。可以在流模式下使用。                 |
| Glob模式 ✅| 'path/*.jpg'                          | str              | 使用Glob模式匹配多个文件。使用`*`字符作为通配符。可以在流模式下使用。|
| YouTube视频 ✅ | 'https://youtu.be/LNwODJXcvt4'    | str              | YouTube视频的URL。可以在流模式下使用。                     |
| 流媒体 ✅  | 'rtsp://example.com/media.mp4'       | str              | 支持RTSP、RTMP、TCP等流媒体协议的URL或IP地址。可以在流模式下使用。 |
| 多流 ✅    |

'list.streams'                           | str or Path      | `*.streams`文本文件，每行一个流媒体URL，例如可以同时运行8个流，批处理大小为8。可以在流模式下使用。|

### 使用技巧

- **流模式** (`stream=True`): 当处理长视频或大数据集时，使用流模式可以有效地管理内存。这种方式不会将所有帧或数据点加载到内存中，而是使用生成器逐个产生结果，这样只保持当前帧或数据点的结果在内存中，大大减少内存消耗，防止内存溢出问题。
- **非流模式** (`stream=False`): 当输入较小，或者需要一次性处理并获取所有结果时使用。所有结果将存储在内存中，这可能会快速增加内存使用，对于大量输入可能导致内存溢出。



## 推理

`model.predict()` 函数接受多个参数，在推理时可以传入这些参数来覆盖默认设置：

### 示例

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n模型
model = YOLO('yolov8n.pt')

# 使用参数在 'bus.jpg' 上运行推理
model.predict('bus.jpg', save=True, imgsz=320, conf=0.5)
```



### 推理参数

|    参数名     |     类型     |        默认值        | 描述                                                         |
| :-----------: | :----------: | :------------------: | ------------------------------------------------------------ |
|    source     |     str      | 'ultralytics/assets' | 指定推理的数据源。可以是图像路径、视频文件、目录、URL或实时源的设备ID。支持多种格式和来源，使其可以灵活应用于不同类型的输入。 |
|     conf      |    float     |         0.25         | 设置检测的最小置信度阈值。低于此阈值的对象将被忽略。调整此值可以帮助减少误报。 |
|      iou      |    float     |         0.7          | 非极大抑制（NMS）的交集超过联合（IoU）阈值。较低值通过消除重叠的框来减少检测数量，有助于减少重复项。 |
|     imgsz     | int 或 tuple |         640          | 定义推理的图像大小。可以是单个整数640用于正方形缩放，或者是（高度，宽度）元组。适当的大小可以提高检测精度和处理速度。 |
|     half      |     bool     |        False         | 启用半精度（FP16）推理，可以在对精度影响最小的情况下加速GPU支持的模型推理。 |
|    device     |     str      |         None         | 指定推理的设备（例如，cpu, cuda:0 或 0）。允许用户在CPU、特定GPU或其他计算设备之间选择进行模型执行。 |
|    max_det    |     int      |         300          | 每张图像允许的最大检测数量。限制模型在单次推理中可以检测到的总物体数量，防止在密集场景中产生过多输出。 |
|  vid_stride   |     int      |          1           | 视频输入的帧距离。允许在视频中跳过帧以加速处理，但以牺牲时间分辨率为代价。值为1时处理每一帧，较高的值将跳过帧。 |
| stream_buffer |     bool     |        False         | 决定在处理视频流时是否应缓冲所有帧（True），或模型应返回最新帧（False）。适用于实时应用程序。 |
|   visualize   |     bool     |        False         | 在推理期间激活模型特征的可视化，提供对模型“所看到的”内容的洞察。用于调试和模型解释。 |
|    augment    |     bool     |        False         | 启用测试时增强（TTA），可能会提高检测的稳健性，但以牺牲推理速度为代价。 |
| agnostic_nms  |     bool     |        False         | 启用类不可知的非极大抑制（NMS），它合并不同类别的重叠框。在类别重叠常见的多类检测场景中很有用。 |
|    classes    |  list[int]   |         None         | 过滤预测到的一组类别ID。只有属于指定类别的检测将被返回。用于专注于多类检测任务中相关的对象。 |
| retina_masks  |     bool     |        False         | 如果模型中可用，使用高分辨率的分割掩模。这可以提高分割任务的掩模质量，提供更细致的细节。 |
|     embed     |  list[int]   |         None         | 指定从哪些层提取特征向量或嵌入。用于聚类或相似性搜索等下游任务。 |



### 可视化参数

|   参数名    |    类型     | 默认值 | 描述                                                         |
| :---------: | :---------: | :----: | :----------------------------------------------------------- |
|    show     |    bool     | False  | 如果为True，将在窗口中显示带注释的图像或视频。在开发或测试期间用于即时的视觉反馈。 |
|    save     |    bool     | False  | 允许将带注释的图像或视频保存到文件中。用于文档化、进一步分析或分享结果。 |
| save_frames |    bool     | False  | 在处理视频时，将单个帧保存为图像。用于提取特定帧或进行逐帧详细分析。 |
|  save_txt   |    bool     | False  | 将检测结果保存在文本文件中，遵循格式[class] [x_center] [y_center] [width] [height] [confidence]。用于与其他分析工具集成。 |
|  save_conf  |    bool     | False  | 在保存的文本文件中包含置信度分数。增强了后处理和分析的详细信息。 |
|  save_crop  |    bool     | False  | 保存检测到的对象的裁剪图像。用于数据集增强、分析或为特定对象创建聚焦的数据集。 |
| show_labels |    bool     |  True  | 在视觉输出中显示每个检测的标签。提供对检测到的对象的直接理解。 |
|  show_conf  |    bool     |  True  | 在标签旁边显示每个检测的置信度分数。提供关于模型对每次检测的确定性的洞察。 |
| show_boxes  |    bool     |  True  | 在检测到的对象周围绘制边界框。对于视觉识别和定位图像或视频帧中的对象至关重要。 |
| line_width  | None 或 int |  None  | 指定边界框的线宽。如果为None，则线宽会根据图像大小自动调整。提供视觉自定义以增强清晰度。 |




## 图像和视频格式
YOLOv8支持多种图像和视频格式，如在 `ultralytics/data/utils.py` 中指定。下面的表格展示了有效的后缀名和示例预测命令。

### 图像
以下表格包含了Ultralytics支持的图像格式。

| 图像后缀 | 示例预测命令               | 参考                         |
|----------|---------------------------|------------------------------|
| .bmp     | `yolo predict source=image.bmp` | 微软BMP文件格式              |
| .dng     | `yolo predict source=image.dng` | Adobe DNG                   |
| .jpeg    | `yolo predict source=image.jpeg`| JPEG                        |
| .jpg     | `yolo predict source=image.jpg` | JPEG                        |
| .mpo     | `yolo predict source=image.mpo` | 多图像对象                   |
| .png     | `yolo predict source=image.png` | 便携式网络图形               |
| .tif     | `yolo predict source=image.tif` | 标签图像文件格式             |
| .tiff    | `yolo predict source=image.tiff`| 标签图像文件格式             |
| .webp    | `yolo predict source=image.webp`| WebP                        |
| .pfm     | `yolo predict source=image.pfm` | 便携式浮点图                |

### 视频
以下表格包含了Ultralytics支持的视频格式。

| 视频后缀 | 示例预测命令               | 参考                         |
|----------|---------------------------|------------------------------|
| .asf     | `yolo predict source=video.asf` | 高级系统格式                |
| .avi     | `yolo predict source=video.avi` | 音视频交错格式              |
| .gif     | `yolo predict source=video.gif` | 图形交换格式                |
| .m4v     | `yolo predict source=video.m4v` | MPEG-4 第14部分             |
| .mkv     | `yolo predict source=video.mkv` | Matroska                    |
| .mov     | `yolo predict source=video.mov` | QuickTime文件格式           |
| .mp4     | `yolo predict source=video.mp4` | MPEG-4 第14部分 - 维基百科  |
| .mpeg    | `yolo predict source=video.mpeg`| MPEG-1 第2部分              |
| .mpg     | `yolo predict source=video.mpg` | MPEG-1 第2部分              |
| .ts      | `yolo predict source=video.ts`  | MPEG传输流                 |
| .wmv     | `yolo predict source=video.wmv` | Windows媒体视频             |
| .webm    | `yolo predict source=video.webm`| WebM项目                    |




### 结果对象属性

| 属性名      | 类型              | 描述                                                         |
|:-------:|:---------------:|------------------------------------------------------------|
| orig_img | numpy.ndarray   | 原始图像，以numpy数组的形式。                                       |
| orig_shape | tuple          | 原始图像的形状，格式为（高度，宽度）。                                 |
| boxes    | Boxes, optional | 包含检测边界框的Boxes对象。                                           |
| masks    | Masks, optional | 包含检测掩模的Masks对象。                                           |
| probs    | Probs, optional | 包含每个类别分类任务的概率的Probs对象。                                 |
| keypoints | Keypoints, optional | 包含每个对象检测到的关键点的Keypoints对象。                          |
| obb      | OBB, optional   | 包含定向边界框的OBB对象。                                            |
| speed    | dict            | 一个字典，包含按图像计算的预处理、推理和后处理速度，单位为毫秒。                  |
| names    | dict            | 一个包含类名的字典。                                                 |
| path     | str             | 图像文件的路径。                                                   |





## 处理结果
所有Ultralytics的 `predict()` 调用都将返回一个结果对象列表：

### 结果

以下是一些使用YOLOv8预训练模型进行推理的代码示例：

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n模型
model = YOLO('yolov8n.pt')

# 在一张图片上运行推理
results = model('bus.jpg')  # 返回包含1个结果对象的列表
results = model(['bus.jpg', 'zidane.jpg'])  # 返回包含2个结果对象的列表
```


### 结果对象方法

| 方法名    | 返回类型      | 描述                                                         |
| --------- | ------------- | ------------------------------------------------------------ |
| update    | None          | 更新Results对象的boxes, masks和probs属性。                   |
| cpu       | Results       | 返回一个所有张量都在CPU内存上的Results对象的副本。           |
| numpy     | Results       | 返回一个所有张量转换为numpy数组的Results对象的副本。         |
| cuda      | Results       | 返回一个所有张量都在GPU内存上的Results对象的副本。           |
| to        | Results       | 返回一个所有张量都在指定设备和数据类型上的Results对象的副本。 |
| new       | Results       | 返回一个具有相同图像、路径和类名的新Results对象。            |
| plot      | numpy.ndarray | 绘制检测结果。返回一个带注释图像的numpy数组。                |
| show      | None          | 在屏幕上显示带注释的结果。                                   |
| save      | None          | 将带注释的结果保存到文件中。                                 |
| verbose   | str           | 返回每个任务的日志字符串。                                   |
| save_txt  | None          | 将预测保存到txt文件中。                                      |
| save_crop | None          | 将裁剪的预测保存到save_dir/cls/file_name.jpg。               |
| tojson    | str           | 将对象转换为JSON格式。                                       |



### `Boxes` 类的使用示例

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n模型
model = YOLO('yolov8n.pt')

# 在图像上运行推理
results = model('bus.jpg')  # 结果列表

# 查看结果
for r in results:
    print(r.boxes)  # 打印包含检测边界框的Boxes对象
```

### `Boxes` 类的方法和属性

| 名称     | 类型             | 描述                                                                         |
|--------|----------------|----------------------------------------------------------------------------|
| cpu()  | 方法            | 将对象移动到CPU内存。                                                         |
| numpy()| 方法            | 将对象转换为numpy数组。                                                       |
| cuda() | 方法            | 将对象移动到CUDA内存。                                                        |
| to()   | 方法            | 将对象移动到指定的设备。                                                       |
| xyxy   | 属性 (torch.Tensor) | 返回边界框的xyxy格式。                                                        |
| conf   | 属性 (torch.Tensor) | 返回边界框的置信度值。                                                        |
| cls    | 属性 (torch.Tensor) | 返回边界框的类别值。                                                          |
| id     | 属性 (torch.Tensor) | 返回边界框的跟踪ID（如果可用）。                                                  |
| xywh   | 属性 (torch.Tensor) | 返回边界框的xywh格式。                                                        |
| xyxyn  | 属性 (torch.Tensor) | 返回边界框的xyxy格式，坐标通过原始图像大小归一化。                                        |
| xywhn  | 属性 (torch.Tensor) | 返回边界框的xywh格式，坐标通过原始图像大小归一化。                                        |



### `Masks` 类的使用示例

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n-seg 分割模型
model = YOLO('yolov8n-seg.pt')

# 在图像上运行推理
results = model('bus.jpg')  # 结果列表

# 查看结果
for r in results:
    print(r.masks)  # 打印包含检测到的实例掩模的Masks对象
```

### `Masks` 类的方法和属性


| 名称   | 类型               | 描述                                               |
|------|------------------|--------------------------------------------------|
| cpu() | 方法              | 返回CPU内存上的掩模张量。                                   |
| numpy() | 方法            | 将掩模张量转换为numpy数组。                                |
| cuda() | 方法             | 返回GPU内存上的掩模张量。                                   |
| to()  | 方法              | 将掩模张量移至指定的设备和数据类型。                            |
| xyn   | 属性 (torch.Tensor) | 以张量形式表示的归一化段列表。                                |
| xy    | 属性 (torch.Tensor) | 以像素坐标形式表示的段列表，以张量形式表示。     


### `Keypoints` 类的使用示例

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n-pose 姿态模型
model = YOLO('yolov8n-pose.pt')

# 在图像上运行推理
results = model('bus.jpg')  # 结果列表

# 查看结果
for r in results:
    print(r.keypoints)  # 打印包含检测到的关键点的Keypoints对象
```

### `Keypoints` 类的方法和属性

| 名称   | 类型               | 描述                                               |
|------|------------------|--------------------------------------------------|
| cpu() | 方法              | 返回CPU内存上的关键点张量。                                 |
| numpy() | 方法            | 将关键点张量转换为numpy数组。                              |
| cuda() | 方法             | 返回GPU内存上的关键点张量。                                 |
| to()  | 方法              | 将关键点张量移至指定的设备和数据类型。                          |
| xyn   | 属性 (torch.Tensor) | 以张量形式表示的归一化关键点列表。                          |
| xy    | 属性 (torch.Tensor) | 以像素坐标形式表示的关键点列表，以张量形式表示。                |
| conf  | 属性 (torch.Tensor) | 如果可用，返回关键点的置信度值，否则为None。                   |


### `Probs` 类的使用示例

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n-cls 分类模型
model = YOLO('yolov8n-cls.pt')

# 在图像上运行推理
results = model('bus.jpg')  # 结果列表

# 查看结果
for r in results:
    print(r.probs)  # 打印包含检测到的类别概率的Probs对象
```

### `Probs` 类的方法和属性


| 名称       | 类型               | 描述                                             |
|----------|------------------|------------------------------------------------|
| cpu()    | 方法              | 返回CPU内存上的概率张量的副本。                           |
| numpy()  | 方法              | 将概率张量转换为numpy数组的副本。                        |
| cuda()   | 方法              | 返回GPU内存上的概率张量的副本。                           |
| to()     | 方法              | 将概率张量移至指定的设备和数据类型。                      |
| top1     | 属性 (int)         | 返回概率最高的1个类的索引。                              |
| top5     | 属性 (list[int])   | 返回概率最高的5个类的索引列表。                          |
| top1conf | 属性 (torch.Tensor)| 返回最高类的置信度。                                    |
| top5conf | 属性 (torch.Tensor)| 返回概率最高的5个类的置信度。                            |


### `OBB` 类的使用示例

```python
from ultralytics import YOLO

# 加载预训练的YOLOv8n-obb 模型
model = YOLO('yolov8n-obb.pt')

# 在图像上运行推理
results = model('bus.jpg')  # 结果列表

# 查看结果
for r in results:
    print(r.obb)  # 打印包含定向检测边界框的OBB对象
```

### `OBB` 类的方法和属性

| 名称       | 类型               | 描述                                                               |
|----------|------------------|------------------------------------------------------------------|
| cpu()    | 方法              | 将对象移动到CPU内存。                                                   |
| numpy()  | 方法              | 将对象转换为numpy数组。                                                |
| cuda()   | 方法              | 将对象移动到CUDA内存。                                                  |
| to()     | 方法              | 将对象移动到指定设备。                                                  |
| conf     | 属性 (torch.Tensor)| 返回边界框的置信度值。                                                  |
| cls      | 属性 (torch.Tensor)| 返回边界框的类别值。                                                    |
| id       | 属性 (torch.Tensor)| 返回边界框的跟踪ID（如果可用）。                                            |
| xyxy     | 属性 (torch.Tensor)| 返回水平边界框的xyxy格式。                                                |
| xywhr    | 属性 (torch.Tensor)| 返回旋转边界框的xywhr格式。                                               |
| xyxyxyxy | 属性 (torch.Tensor)| 返回旋转边界框的xyxyxyxy格式。                                             |
| xyxyxyxyn| 属性 (torch.Tensor)| 返回根据图像大小归一化的旋转边界框的xyxyxyxy格式。                           |




### `plot()` 方法的使用示例

```python
from PIL import Image
from ultralytics import YOLO

# 加载预训练的YOLOv8n模型
model = YOLO('yolov8n.pt')

# 在 'bus.jpg' 上运行推理
results = model(['bus.jpg', 'zidane.jpg'])  # 结果列表

# 可视化结果
for i, r in enumerate(results):
    # 绘制结果图像
    im_bgr = r.plot()  # BGR顺序的numpy数组
    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB顺序的PIL图像

    # 在支持的环境中显示结果
    r.show()

    # 将结果保存到磁盘
    r.save(filename=f'results{i}.jpg')
```

### `plot()` 方法的参数

| 参数名       | 类型           | 描述                                            | 默认值       |
|-----------|--------------|-----------------------------------------------|-----------|
| conf      | bool         | 是否包含检测置信度分数。                               | True      |
| line_width| float        | 边界框的线宽。如果为None，则随图像大小缩放。                 | None      |
| font_size | float        | 文本字体大小。如果为None，则随图像大小缩放。                 | None      |
| font      | str          | 文本注释的字体名称。                                   | 'Arial.ttf'|
| pil       | bool         | 是否返回作为PIL图像对象的图片。                            | False     |
| img       | numpy.ndarray| 用于绘图的替代图像。如果为None，则使用原始图像。                | None      |
| im_gpu    | torch.Tensor | 用于加速掩模绘图的GPU加速图像。格式：(1, 3, 640, 640)。        | None      |
| kpt_radius| int          | 绘制的关键点的半径。                                    | 5         |
| kpt_line  | bool         | 是否用线连接关键点。                                    | True      |
| labels    | bool         | 是否在注释中包含类别标签。                                 | True      |
| boxes     | bool         | 是否在图像上覆盖边界框。                                  | True      |
| masks     | bool         | 是否在图像上覆盖掩模。                                   | True      |
| probs     | bool         | 是否包含分类概率。                                      | True      |
| show      | bool         | 是否使用默认图像查看器直接显示带注释的图像。                       | False     |
| save      | bool         | 是否将带注释的图像保存到由filename指定的文件中。                   | False     |
| filename  | str          | 如果save为True，带注释的图像保存的文件路径和名称。                 | None      |



以下是YOLOv8模型在多线程环境中确保线程安全进行推理的方法，以及如何使用YOLOv8在视频流中进行帧推理的示例。这些信息将帮助您在并发执行多个模型时避免冲突，并确保可靠和一致的输出。

### 线程安全的推理

在多线程应用程序中使用YOLO模型时，为了确保线程安全，重要的是在每个线程中实例化独立的模型对象，或者使用线程本地存储来防止冲突：

```python
from ultralytics import YOLO
from threading import Thread

def thread_safe_predict(image_path):
    # 在线程中实例化一个新模型
    local_model = YOLO("yolov8n.pt")
    results = local_model.predict(image_path)
    # 处理结果

# 启动线程，每个线程拥有自己的模型实例
Thread(target=thread_safe_predict, args=("image1.jpg",)).start()
Thread(target=thread_safe_predict, args=("image2.jpg",)).start()
```

为了更深入地了解YOLO模型的线程安全推理并获得步骤指导，请参考我们的YOLO线程安全推理指南。这个指南将为您提供避免常见陷阱并确保您的多线程推理顺利进行所需的所有信息。



### 视频流中的推理循环

以下是使用OpenCV（cv2）和YOLOv8在视频帧上运行推理的Python脚本。这个脚本假设您已经安装了必要的包（opencv-python和ultralytics）：

```python
import cv2
from ultralytics import YOLO

# 加载YOLOv8模型
model = YOLO('yolov8n.pt')

# 打开视频文件
video_path = "path/to/your/video/file.mp4"
cap = cv2.VideoCapture(video_path)

# 循环处理视频帧
while cap.isOpened():
    # 从视频读取一帧
    success, frame = cap.read()

    if success:
        # 在帧上运行YOLOv8推理
        results = model(frame)

        # 在帧上可视化结果
        annotated_frame = results[0].plot()

        # 显示带注释的帧
        cv2.imshow("YOLOv8 Inference", annotated_frame)

        # 如果按下'q'则退出循环
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
    else:
        # 如果视频结束则退出循环
        break

# 释放视频捕捉对象并关闭显示窗口
cap.release()
cv2.destroyAllWindows()
```

这个脚本将在视频的每一帧上运行预测，可视化结果，并在窗口中显示。通过按下'q'可以退出循环。