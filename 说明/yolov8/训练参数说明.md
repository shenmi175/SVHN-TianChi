
## 使用示例
在COCO8数据集上训练YOLOv8n模型100个周期，图像尺寸为640。训练设备可以使用 `device` 参数指定。如果没有指定参数，且GPU可用，将默认使用 GPU device=0；否则，将使用 CPU。下方“参数”部分列出了全部训练参数。

### 单GPU和CPU训练示例

设备将自动确定。如果GPU可用，则将使用GPU；否则，训练将在CPU上开始。

#### Python
```python
from ultralytics import YOLO

# 加载模型
model = YOLO('yolov8n.yaml')  # 从YAML构建新模型
model = YOLO('yolov8n.pt')    # 加载预训练模型（推荐用于训练）
model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # 从YAML构建并转移权重

# 训练模型
results = model.train(data='coco8.yaml', epochs=100, imgsz=640)
```

### 多GPU训练
多GPU训练可以通过分布训练负载到多个GPU上，更有效地利用可用的硬件资源。这一特性通过Python API和命令行界面都可以使用。要启用多GPU训练，请指定你希望使用的GPU设备ID。

#### 多GPU训练示例

要使用2个GPU进行训练，CUDA设备0和1，使用以下命令。根据需要扩展到更多GPU。

#### Python
```python
from ultralytics import YOLO

# 加载模型
model = YOLO('yolov8n.pt')  # 加载预训练模型（推荐用于训练）

# 使用2个GPU训练模型
results = model.train(data='coco8.yaml', epochs=100, imgsz=640, device=[0, 1])
```



## 恢复中断的训练
从先前保存的状态恢复训练是处理深度学习模型时的一个关键功能。这在多种情况下非常有用，比如当训练过程意外中断，或者当你希望用新数据或更多周期继续训练模型时。

恢复训练时，Ultralytics YOLO会从最后保存的模型加载权重，并且恢复优化器状态、学习率调度器和周期数。这使你可以无缝地从中断处继续训练过程。

在Ultralytics YOLO中，你可以通过在调用 `train` 方法时设置 `resume` 参数为 `True` 并指定包含部分训练模型权重的 `.pt` 文件的路径来轻松恢复训练。

以下是使用Python和命令行恢复中断训练的示例：

### 恢复训练示例

#### Python
```python
from ultralytics import YOLO

# 加载模型
model = YOLO('path/to/last.pt')  # 加载部分训练的模型

# 恢复训练
results = model.train(resume=True)
```

通过设置 `resume=True`，`train` 函数将从中断的地方继续训练，使用存储在 `path/to/last.pt` 文件中的状态。如果省略 `resume` 参数或将其设置为 `False`，则 `train` 函数将启动一个新的训练会话。

请记住，默认情况下，检查点在每个周期结束时保存，或者使用 `save_period` 参数按固定间隔保存，因此你必须完成至少一个周期才能恢复训练。




## 训练设置

训练设置包括在训练过程中使用的各种超参数和配置。这些设置会影响模型的性能、速度和准确度。关键的训练设置包括批量大小、学习率、动量和权重衰减。此外，选择优化器、损失函数和训练数据集的组成也可以影响训练过程。仔细调整和实验这些设置对于优化性能至关重要。

| 参数             | 默认值 | 描述                                                                                                       |
|------------------|--------|----------------------------------------------------------------------------------------------------------|
| model            | 无     | 指定用于训练的模型文件。接受一个指向预训练模型（.pt）或配置文件（.yaml）的路径。对定义模型结构或初始化权重至关重要。 |
| data             | 无     | 数据集配置文件的路径（例如，coco8.yaml）。该文件包含特定数据集的参数，包括训练和验证数据的路径、类别名称和类别数量。   |
| epochs           | 100    | 训练周期总数。每个周期代表对整个数据集的完整遍历。调整这个值可以影响训练持续时间和模型性能。                       |
| time             | 无     | 训练的最大时间（小时）。如果设置，这将覆盖epochs参数，允许在指定的持续时间后自动停止训练。对于时间受限的训练场景很有用。 |
| patience         | 100    | 在验证指标没有改进的情况下等待的周期数，用于在性能停滞时提前停止训练。有助于通过停止训练来防止过拟合。                 |
| batch            | 16     | 训练的批量大小，表示在模型内部参数更新之前处理的图像数量。AutoBatch（batch=-1）根据GPU内存可用性动态调整批量大小。     |
| imgsz            | 640    | 训练的目标图像大小。所有图像都被调整到这个尺寸，然后输入模型。影响模型准确性和计算复杂度。                      |
| save             | True   | 启用训练检查点和最终模型权重的保存。对于恢复训练或模型部署很有用。                                          |
| save_period      | -1     | 保存模型检查点的频率（以周期数指定）。值为-1时禁用此功能。在长时间训练过程中保存中间模型很有用。                  |
| cache            | False  | 启用数据集图像在内存中（True/ram）、磁盘上（disk）的缓存，或禁用（False）。通过减少磁盘I/O提高训练速度，但增加内存使用。|
| device           | 无     | 指定训练的计算设备：单个GPU（device=0）、多个GPU（device=0,1）、CPU（device=cpu）或苹果硅芯片上的MPS（device=mps）。 |
| workers          | 8      | 数据加载的工作线程数（如果是多GPU训练，则每个RANK）。影响数据预处理和输入模型的速度，特别在多GPU设置中很有用。        |
| project          | 无     | 存放训练输出的项目目录的名称。允许有组织地存储不同实验。                                                   |
| name             | 无     | 训练运行的名称。用于在项目文件夹中创建一个子目录，在其中存储训练日志和输出。                                  |
| exist_ok         | False  | 如果为True，则允许覆盖现有的项目/名称目录。对于不需要手动清除之前输出的迭代实验很有用。                         |
| pretrained       | True   | 确定是否从预训练模型开始训练。可以是布尔值，或者是加载权重的特定模型的字符串路径。提高训练效率和模型性能。         |
| optimizer        | 'auto' | 训练的优化器选择。选项包括SGD、Adam、AdamW、NAdam、RAdam、RMSProp等，或者根据模型配置自动选择。影响收敛速度和稳定性。  |
| verbose          | False  | 启用训练期间的详细输出，提供详细的日志和进度更新。对于调试和密切监控训练过程很有用。                            |
| seed             | 0      | 设置训练的随机种子，确保在相同配置的运行中结果可复现。                                                      |
| deterministic    | True   | 强制使用确定性算法，确保可复现性，但由于限制了非确定性算法，可能会影响性能和速度。                             |
| single_cls       | False  | 在训练时将多类数据集中的所有类别视为单一类别。对于二分类任务或当关注对象存在而不是分类时有用。                    |
| rect             | False  | 启用矩形训练，优化批次组成以最小化填充。可以提高效率和速度，但可能影响模型准确性。                             |
| cos_lr           | False  | 使用余弦学习率调度器，在周期内按照余弦曲线调整学习率。帮助更好地管理学习率以实现更好的收敛。                     |
| close_mosaic     | 10     | 在最后N个周期禁用马赛克数据增强，以稳定训练结束前的训练。设置为0禁用此功能。                                  |
| resume           | False  | 从最后保存的检查点恢复训练。自动加载模型权重、优化器状态和周期计数，无缝继续训练。                             |
| amp              | True   | 启用自动混合精度（AMP）训练，减少内存使用，并且可能在对准确性影响最小的情况下加快训练速度。                    |
| fraction         | 1.0    | 指定用于训练的数据集的一部分。允许在完整数据集的子集上训练，对于实验或资源有限时很有用。                        |
| profile          | False  | 在训练期间启用ONNX和TensorRT速度分析，对于优化模型部署很有用。                                             |
| freeze           | 无     | 冻结模型的前N层或按索引指定的层，减少可训练参数的数量。对于微调或迁移学习很有用。                               |
| lr0              | 0.01   | 初始学习率（例如，SGD=1E-2，Adam=1E-3）。调整这个值对优化过程至关重要，影响模型权重更新的速度。                 |
| lrf              | 0.01   | 最终学习率作为初始率的一部分 =（lr0 * lrf），与调度器结合使用，随时间调整学习率。                              |
| momentum         | 0.937  | SGD的动量因子或Adam优化器的beta1，影响过去梯度在当前更新中的融合。                                         |
| weight_decay     | 0.0005 | L2正则化项，通过惩罚大权重防止过拟合。                                                                       |
| warmup_epochs    | 3.0    | 学习率热身的周期数，逐渐从低值增加学习率到初始学习率，以稳定早期训练。                                       |
| warmup_momentum  | 0.8    | 热身阶段的初始动量，逐渐在热身期间调整到设定的动量。                                                        |
| warmup_bias_lr   | 0.1    | 热身阶段偏差参数的学习率，帮助在最初的周期中稳定模型训练。                                                  |
| box              | 7.5    | 损失函数中边框损失部分的权重，影响准确预测边框坐标的重视程度。                                               |
| cls              | 0.5    | 总损失函数中分类损失的权重，影响相对于其他组成部分正确类别预测的重要性。                                      |
| dfl              | 1.5    | 分布焦点损失的权重，用于某些YOLO版本的细粒度分类。                                                           |
| pose             | 12.0   | 用于姿态估计训练的模型中姿态损失的权重，影响准确预测姿态关键点的重视程度。                                   |
| kobj             | 2.0    | 姿态估计模型中关键点对象性损失的权重，平衡检测置信度与姿态准确性。                                           |
| label_smoothing  | 0.0    | 应用标签平滑，将硬标签软化为目标标签与标签上均匀分布的混合，可以改善泛化。                                     |
| nbs              | 64     | 用于损失归一化的标称批量大小。                                                                               |
| overlap_mask     | True   | 决定训练期间分割掩码是否应该重叠，适用于实例分割任务。                                                       |
| mask_ratio       | 4      | 分割掩码的下采样比率，影响训练期间使用的掩码分辨率。                                                         |
| dropout          | 0.0    | 分类任务中用于正则化的丢弃率，通过在训练过程中随机省略单元防止过拟合。                                        |
| val              | True   | 启用训练期间的验证，允许定期对单独数据集的模型性能进行评估。                                                  |
| plots            | False  | 生成并保存训练和验证指标的图表，以及预测示例，提供模型性能和学习进程的视觉洞察。                                |





## 数据增强设置和超参数

数据增强技术对于提高 YOLO 模型的鲁棒性和性能至关重要，通过在训练数据中引入变化，帮助模型更好地泛化到未见过的数据。下表概述了每个增强参数的目的和效果：

|     参数      | 类型     |   默认值    | 范围        | 描述                                                         |
| :--------------------: | :------- | :---------: | :---------- | :----------------------------------------------------------- |
|     hsv_h     | 浮点型   |    0.015    | 0.0 - 1.0   | 调整图像的色调，按照色轮的一小部分变化，引入颜色的多样性。帮助模型在不同的光照条件下泛化。 |
|     hsv_s     | 浮点型 |     0.7     | 0.0 - 1.0   | 以一定比例改变图像的饱和度，影响颜色的强度。对模拟不同环境条件很有用。 |
|     hsv_v     | 浮点型 |     0.4     | 0.0 - 1.0   | 以一定比例修改图像的值（亮度），帮助模型在不同的照明条件下表现良好。 |
|    degrees    | 浮点型 |     0.0     | -180 - +180 | 随机旋转图像，范围在指定的度数内，提高模型识别不同方向对象的能力。 |
|   translate   | 浮点型 |     0.1     | 0.0 - 1.0   | 以图像大小的一定比例水平和垂直移动图像，帮助学习检测部分可见的对象。 |
|     scale     | 浮点型 |     0.5     | >=0.0       | 通过一个增益因子缩放图像，模拟摄像机不同距离的对象。         |
|     shear     | 浮点型 |     0.0     | -180 - +180 | 以指定的度数剪切图像，模仿从不同角度观看对象的效果。         |
|  perspective  | 浮点型 |     0.0     | 0.0 - 0.001 | 对图像应用随机透视变换，增强模型理解三维空间中对象的能力。   |
|    flipud     | 浮点型 |     0.0     | 0.0 - 1.0   | 以指定的概率上下翻转图像，增加数据多样性而不影响对象特性。   |
|    fliplr     | 浮点型 |     0.5     | 0.0 - 1.0   | 以指定的概率左右翻转图像，有助于学习对称物体并增加数据集多样性。 |
|      bgr      | 浮点型 |     0.0     | 0.0 - 1.0   | 以指定的概率将图像通道从 RGB 翻转到 BGR，有助于提高对错误通道排序的鲁棒性。 |
|    mosaic     | 浮点型 |     1.0     | 0.0 - 1.0   | 将四个训练图像组合成一个，模拟不同的场景组合和对象交互。对于复杂场景理解非常有效。 |
|     mixup     | 浮点型 |     0.0     | 0.0 - 1.0   | 混合两个图像及其标签，创建一个复合图像。通过引入标签噪声和视觉多样性，增强模型的泛化能力。 |
|  copy_paste   | 浮点型 |     0.0     | 0.0 - 1.0   | 从一幅图像中复制对象并粘贴到另一幅图像上，有助于增加对象实例数并学习对象遮挡。 |
| auto_augment  | 字符串 | randaugment | -           | 自动应用预定义的增强策略（randaugment、autoaugment、augmix），通过多样化视觉特征，为分类任务进行优化。 |
|    erasing    | 浮点型 |     0.4     | 0.0 - 0.9   | 在分类训练期间随机擦除图像的一部分，鼓励模型关注不那么明显的特征进行识别。 |
| crop_fraction | 浮点型 |     1.0     | 0.1 - 1.0   | 将分类图像裁剪到其大小的一部分，以强调中心特征并适应对象规模，减少背景干扰。 |

这些设置可以根据数据集和手头任务的具体要求进行调整。通过尝试不同的值，可以帮助找到最佳的增强策略，从而提高模型性能。



## 日志记录
在训练YOLOv8模型时，跟踪模型随时间的性能变化可能非常有价值。这就是日志记录发挥作用的地方。Ultralytics的YOLO支持三种类型的日志记录器 - Comet、ClearML和TensorBoard。

要使用日志记录器，从上述代码片段中的下拉菜单中选择一个并运行它。所选的日志记录器将被安装并初始化。

### Comet
Comet是一个平台，允许数据科学家和开发人员跟踪、比较、解释和优化实验和模型。它提供了实时指标、代码差异和超参数跟踪等功能。

#### 使用Comet的示例

```python
# pip install comet_ml
import comet_ml

comet_ml.init()
```

请记得在Comet网站上登录您的Comet账户并获取您的API密钥。您需要将此添加到您的环境变量或脚本中，以记录您的实验。


## ClearML
ClearML是一个开源平台，自动化实验跟踪并帮助高效共享资源。它旨在帮助团队更有效地管理、执行和复现他们的机器学习工作。

### 使用ClearML的示例

```python
# pip install clearml
import clearml

clearml.browser_login()
```

运行此脚本后，您需要在浏览器中登录到您的ClearML账户并认证您的会话。

## TensorBoard
TensorBoard是TensorFlow的可视化工具包。它允许您可视化您的TensorFlow图，绘制关于图执行的量化指标，并显示像通过它传递的图像等附加数据。

### 在Google Colab中使用TensorBoard的示例

#### 命令行接口（CLI）

```plaintext
load_ext tensorboard
tensorboard --logdir ultralytics/runs  # 替换为'runs'目录
```

### 本地使用TensorBoard的示例

要在本地使用TensorBoard，请运行下面的命令并在 http://localhost:6006/ 查看结果。

#### 命令行接口（CLI）

```plaintext
tensorboard --logdir ultralytics/runs  # 替换为'runs'目录
```

这将加载TensorBoard并将其指向保存您训练日志的目录。

在设置好您的日志记录器后，您可以继续进行模型训练。所有训练指标都将自动记录在您选择的平台上，您可以访问这些日志以监控您的模型随时间的性能，比较不同模型，并识别改进的领域。

